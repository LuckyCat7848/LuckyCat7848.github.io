---
layout: post
title:  GPUImage学习总结
date:   2017-03-18 01:43:12 +0800
categories: 技术
tag: Object-C
---


* TOC
{:toc}




一、介绍
===========
GPUImage是Brad Larson在github托管的开源项目。

GPUImage是一个基于GPU图像和视频处理的开源iOS框架，提供各种各样的图像处理滤镜，并且支持照相机和摄像机的实时滤镜； 基于GPU的图像加速，因此可以加速对实时摄像头视频、电影以及image的滤镜和其它效果处理，并且能够自定义图像滤镜。另外， GPUImage支持ARC。

使用GPUImage处理图片比Core Image更简单，只需要将过滤器赋给图片对象即可，不用考虑context或者设备等其他问题。GPUImage提供了除高斯模糊外的其他几种不同效果的模糊，虽然Core Image也提供了几种模糊效果，但目前在iOS上能用的就只有高斯模糊，而GPUImage可用的有FastBlur, GaussianBlur, GaussianSelectiveBlur 和 BoxBlur。此外，作为开源框架的GPUImage还支持自定义的过滤器。



二、内置滤镜
======
共125个滤镜, 分为四类
Color adjustments: 31 filters, 颜色处理相关
Image processing: 40 filters, 图像处理相关.
Blending modes: 29 filters, 混合模式相关.
Visual effects: 25 filters, 视觉效果相关.


三、分段录制
======
参考[AVFoundation和GPUImage初探](http://www.tuicool.com/articles/FVnumu)。 

分段录制，每次录制都要创建一个movieWriter，每次都会在重新创建movieWriter并将它设置为videoCamera的 audioEncodingTarget 时候，界面都会卡顿一下，这是因为videoCamera默认是不录制声音的，而每次创建movieWriter的时候都用到了 movieWriter.hasAudioTrack = YES，调用这个之后videoCamera会自动去添加声音输入源，准备一些数据，所以这个过程会导致界面卡顿一下，下面这句代码很重要：

```bash
– (BOOL)addAudioInputsAndOutputs;
```

videoCamera的头文件的注释是：录制的时候添加声音，添加输入源和输出源会暂时会使录制暂时卡住，所以在要使用声音的情况下要`先`调用该方法来防止录制被卡住。



四、 GPUImage录制视频
=====
转自[GPUImage 录制视频注意事项](http://blog.sina.com.cn/s/blog_d0c0c80c0102xbo0.html)，感谢[我的个神啊](http://blog.sina.com.cn/u/3502295052)的分享。 

4.1 基本设置
------------------------------------

``` bash
// 创建摄像头
self.videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPreset640x480 cameraPosition:AVCaptureDevicePositionBack];

self.videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait; // 输出图像旋转方式
self.videoCamera.horizontallyMirrorFrontFacingCamera = YES;

// 创建界面显示摄像内容
self.gpuImageView = [[GPUImageView alloc] initWithFrame:frame];
self.gpuImageView.fillMode = kGPUImageFillModePreserveAspectRatioAndFill; // 显示模式充满整个边框
self.gpuImageView.clipsToBounds = YES;
[self.gpuImageView.layer setMasksToBounds:YES];

// 滤镜
self.filter = [[GPUImageBrightnessFilter alloc] init];
self.filter.brightness = 0.1f;
```

4.2 开始录制
------------------------------------

``` bash
// 该句可防止允许声音通过的情况下，避免录制第一帧黑屏闪屏卡顿现象（分段录制里有详解）
[_camera addAudioInputsAndOutputs];

// 配置录制器
NSURL * saveURL = [self fileURLForTempMovieByName:[NSString stringWithFormat:@"%d", videoFileNum]]; // 分段录制,videoFileNum:第几段
self.movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:saveURL  size:CGSizeMake(480.0f, 640.0f)];

self.movieWriter.assetWriter.movieFragmentInterval = kCMTimeInvalid;
self.movieWriter.encodingLiveVideo = YES; // 影响其实是expectsMediaDataInRealTime属性，YES时用于输入流是实时的,比如说摄像头
self.movieWriter.hasAudioTrack = YES; // 开启声音采集
self.movieWriter.shouldPassthroughAudio = YES; // 是否使用源音源

[self.filter addTarget:self.movieWriter]; // 滤镜添加至moviewrite
[self.filter addTarget:self.gpuImageView]; // 滤镜添加gpuimageview
self.videoCamera.audioEncodingTarget = self.movieWriter; // 音频来源是文件

// 开始录制
[self.videoCamera startCameraCapture];
[self.movieWriter startRecording];
```

4.3 停止录制
------------------------------------

``` bash
[self.filter removeTarget:self.movieWriter];
[self.movieWriter finishRecording];
self.videoCamera.audioEncodingTarget = nil;
```

4.4 视频拼接
------------------------------------

- 4.4.1 AVFoundation基本知识点

AVAsset：媒体。

AVAssetTrack：媒体轨道。

AVMutableComposition ：包含了一个或多个给定类型的媒体轨道的容器。 

AVMutableCompositionTrack ：工程文件中的轨道，有音频轨、视频轨等，里面可以插入各种对应的素材。

AVMutableVideoComposition：用来生成video的组合指令，包含多段instruction，可以决定最终视频的尺寸。 

AVMutableVideoCompositionInstruction：决定一个timeRange内每个轨道的状态，包含多个layerInstruction。

AVMutableVideoCompositionLayerInstruction：决定视频轨道的效果:模糊、变形、裁剪,可创建出过渡效果。 


- 4.4.2 分段视频的拼接

``` bash
#pragma mark -
#pragma mark 视频拼接,视频和音频合成 存储为:MergerMovie
- (void)mergeAndSaveMovieWithFirstAsset:(AVAsset * )firstAsset secondAsset:(AVAsset *)secondAsset {
    
    static int mergerFileNum = 1; // 合成后的视频文件个数(因为是递归合成,不便删除上一个,所以有多个文件)
    
    if (firstAsset !=nil && secondAsset!=nil) {
        // 1.创建组合mixComposition,用于合成视频,和声音(要分别创建组合轨道)
        AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
        // 2.创建1和2的视频轨道、音频轨道,都加入组合中mixComposition
        AVMutableCompositionTrack *firstVideoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                                 preferredTrackID:kCMPersistentTrackID_Invalid];
        [firstVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                                 ofTrack:[[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                                  atTime:kCMTimeZero
                                   error:nil];
        AVMutableCompositionTrack *firstAudioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio
                                                                                 preferredTrackID:kCMPersistentTrackID_Invalid];
        [firstAudioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                                 ofTrack:[[firstAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0]
                                  atTime:kCMTimeZero
                                   error:nil];
        
        
        AVMutableCompositionTrack *secondVideoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                                  preferredTrackID:kCMPersistentTrackID_Invalid];
        [secondVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, secondAsset.duration)
                                  ofTrack:[[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                                   atTime:firstAsset.duration
                                    error:nil];
        AVMutableCompositionTrack *secondAudioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio
                                                                                  preferredTrackID:kCMPersistentTrackID_Invalid];
        [secondAudioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, secondAsset.duration)
                                  ofTrack:[[secondAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0]
                                   atTime:firstAsset.duration
                                    error:nil];
        
        // 3.创建AVMutableVideoCompositionInstruction:一个指令，决定一个timeRange内每个轨道的状态，包含多个layerInstruction
        AVMutableVideoCompositionInstruction *mainInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
        mainInstruction.timeRange = CMTimeRangeMake(kCMTimeZero, CMTimeAdd(firstAsset.duration, secondAsset.duration));
        
        // 3-1.创建第一个AVMutableVideoCompositionLayerInstruction:决定视频轨道的效果:模糊、变形、裁剪,可创建出过渡效果
        AVMutableVideoCompositionLayerInstruction *firstlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:firstVideoTrack];
        AVAssetTrack *firstAssetTrack = [[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        UIImageOrientation firstAssetOrientation_  = UIImageOrientationUp;
        BOOL isFirstAssetPortrait_  = NO;
        CGAffineTransform firstTransform = firstAssetTrack.preferredTransform;
        if (firstTransform.a == 0 && firstTransform.b == 1.0 && firstTransform.c == -1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ = UIImageOrientationRight;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 0 && firstTransform.b == -1.0 && firstTransform.c == 1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ =  UIImageOrientationLeft;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == 1.0) {
            firstAssetOrientation_ =  UIImageOrientationUp;
        }
        if (firstTransform.a == -1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == -1.0) {
            firstAssetOrientation_ = UIImageOrientationDown;
        }
        [firstlayerInstruction setTransform:firstAsset.preferredTransform atTime:kCMTimeZero];
        [firstlayerInstruction setOpacity:0.0 atTime:firstAsset.duration];
        
        // 3-2.创建第二个AVMutableVideoCompositionLayerInstruction
        AVMutableVideoCompositionLayerInstruction *secondlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:secondVideoTrack];
        AVAssetTrack *secondAssetTrack = [[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        UIImageOrientation secondAssetOrientation_  = UIImageOrientationUp;
        BOOL isSecondAssetPortrait_ = NO;
        CGAffineTransform secondTransform = secondAssetTrack.preferredTransform;
        if (secondTransform.a == 0 && secondTransform.b == 1.0 && secondTransform.c == -1.0 && secondTransform.d == 0) {
            secondAssetOrientation_= UIImageOrientationRight;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 0 && secondTransform.b == -1.0 && secondTransform.c == 1.0 && secondTransform.d == 0) {
            secondAssetOrientation_ =  UIImageOrientationLeft;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == 1.0) {
            secondAssetOrientation_ =  UIImageOrientationUp;
        }
        if (secondTransform.a == -1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == -1.0) {
            secondAssetOrientation_ = UIImageOrientationDown;
        }
        [secondlayerInstruction setTransform:secondAsset.preferredTransform atTime:firstAsset.duration];
        
        // AVMutableVideoComposition:用来生成video的组合指令,包含多段instruction,可以决定最终视频的尺寸
        // 3-3.AVMutableVideoComposition添加instructions
        mainInstruction.layerInstructions = [NSArray arrayWithObjects:firstlayerInstruction, secondlayerInstruction,nil];
        AVMutableVideoComposition *mainCompositionInst = [AVMutableVideoComposition videoComposition];
        mainCompositionInst.instructions = [NSArray arrayWithObject:mainInstruction];
        mainCompositionInst.frameDuration = CMTimeMake(1, 30);
        
        CGSize naturalSizeFirst, naturalSizeSecond;
        if(isFirstAssetPortrait_){
            naturalSizeFirst = CGSizeMake(firstAssetTrack.naturalSize.height, firstAssetTrack.naturalSize.width);
        } else {
            naturalSizeFirst = firstAssetTrack.naturalSize;
        }
        if(isSecondAssetPortrait_){
            naturalSizeSecond = CGSizeMake(secondAssetTrack.naturalSize.height, secondAssetTrack.naturalSize.width);
        } else {
            naturalSizeSecond = secondAssetTrack.naturalSize;
        }
        
        float renderWidth, renderHeight;
        renderWidth = naturalSizeFirst.width > naturalSizeSecond.width ? naturalSizeFirst.width : naturalSizeSecond.width;
        renderHeight = naturalSizeFirst.height > naturalSizeSecond.height ? naturalSizeFirst.height : naturalSizeSecond.height;
        mainCompositionInst.renderSize = CGSizeMake(renderWidth, renderHeight);
        
        // 4.获取路径
        NSURL *url = [self fileURLForTempMovieByName:[NSString stringWithFormat:@"MergerMovie%d", mergerFileNum]];
        
        // 5.创建AVAssetExportSession,用于导出合成好的视频
        AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:mixComposition
                                                                          presetName:AVAssetExportPresetHighestQuality];
        exporter.outputURL=url;
        exporter.outputFileType = AVFileTypeMPEG4;//AVFileTypeQuickTimeMovie;
        exporter.shouldOptimizeForNetworkUse = YES;
        exporter.videoComposition = mainCompositionInst;
        __weak __typeof(self)weakSelf = self;
        [exporter exportAsynchronouslyWithCompletionHandler:^{
            dispatch_async(dispatch_get_main_queue(), ^{
                mergerFileNum ++;
                if (mergerFileNum < [_videoArray count]) {
                    // 取合成好的视频和下一个,递归进行视频拼接,拼接后和音频合成
                    AVAsset * nextAsset = [AVAsset assetWithURL:[_videoArray objectAtIndex:mergerFileNum]];
                    AVAsset * mergerVideo = [AVAsset assetWithURL:[weakSelf fileURLForTempMovieByName:[NSString stringWithFormat:@"MergerMovie%d", mergerFileNum - 1]]];
                    [weakSelf mergeAndSaveMovieWithFirstAsset:mergerVideo secondAsset:nextAsset];
                } else {
                    // 合成完成,导出
                    mergerFileFinally = [NSString stringWithFormat:@"MergerMovie%d", mergerFileNum - 1];
                    mergerFileNum = 1;
                    [weakSelf exportDidFinish:exporter];
                }
            });
        }];
    }
}
- (void)exportDidFinish:(AVAssetExportSession*)session {
    __weak __typeof(self)weakSelf = self;
    dispatch_async(dispatch_get_main_queue(), ^{
        if (session.status == AVAssetExportSessionStatusCompleted) {
            // 视频拼接成功,取出视频中的音频
            [weakSelf getAudioSound];
        } else {
            UIAlertView *alert = [[UIAlertView alloc] initWithTitle:@"Video Saved" message:[NSString stringWithFormat:@"Saved To File Failed -- %d", session.status]
                                                           delegate:self cancelButtonTitle:@"OK" otherButtonTitles:nil];
            [alert show];
        }
    });
}
```

- 4.4.3 从合成的视频取出音频轨道

``` bash
// 从合成好的视频中获取音频
- (void)getAudioSound {
    AVURLAsset *videoAsset = [AVURLAsset URLAssetWithURL:[self fileURLForTempMovieByName:mergerFileFinally] options:nil];
    AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
    //创建一个组合轨道,类型是AVMediaTypeAudio
    AVMutableCompositionTrack *audioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio
                                                                        preferredTrackID:kCMPersistentTrackID_Invalid];
    
    //获取videoAsset中的音频轨道,插入组合轨道
    [audioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, videoAsset.duration)
                        ofTrack:[[videoAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0] atTime:kCMTimeZero error:nil];
    
    NSString *outFilePath = [[self fileURLForTempSoundByName:@"MergerSound"] path];
    [self exportAudioAsset:audioTrack.asset toFilePath:outFilePath];
}
- (BOOL)exportAudioAsset:(AVAsset *)avAsset toFilePath:(NSString *)filePath {
    AVAssetExportSession *exportSession = [AVAssetExportSession
                                           exportSessionWithAsset:avAsset
                                           presetName:AVAssetExportPresetAppleM4A];
    if (nil == exportSession) return NO;//创建失败，则跳出
    
    exportSession.outputURL = [NSURL fileURLWithPath:filePath]; // output path 新文件路径
    exportSession.outputFileType = AVFileTypeAppleM4A; // output file type 新文件类型
    
    __weak __typeof(self)weakSelf = self;
    [exportSession exportAsynchronouslyWithCompletionHandler:^{ //block
        if (exportSession.status == AVAssetExportSessionStatusCompleted) {
            dispatch_async(dispatch_get_main_queue(), ^{
                // 1.根据 Main.storyboard 的前缀 "Main" 取到storyBoard 的地址
                UIStoryboard *storyBoard = [UIStoryboard storyboardWithName:@"Recording" bundle:[NSBundle mainBundle]];
                // 2.根据事先在storyBoard中设置的 storyBoard ID 来获取相应的 ViewController
                VideoPlayViewController * videoPlay = [storyBoard instantiateViewControllerWithIdentifier:@"VideoPlayViewController"];
                videoPlay.playUrl = [weakSelf fileURLForTempMovieByName:mergerFileFinally];
                videoPlay.playSoundUrl = [weakSelf fileURLForTempSoundByName:@"MergerSound"];
                [weakSelf.navigationController pushViewController:videoPlay animated:YES];
            });
        } else {
            dispatch_async(dispatch_get_main_queue(), ^{
                UIAlertView *alert = [[UIAlertView alloc] initWithTitle:@"Audio Saved" message:@"Saved To File Failed"
                                                               delegate:self cancelButtonTitle:@"OK" otherButtonTitles:nil];
                [alert show];
            });
        }
    }];
    return YES;
}
```

- 4.4.4 调用合成视频方法：

``` bash
// 取第1,2段,进行视频拼接,拼接后取出完整音频,传界面
AVAsset *firstAsset = [AVAsset assetWithURL:_videoArray[0]];
AVAsset *secondAsset = [AVAsset assetWithURL:_videoArray[1]];
[self mergeAndSaveMovieWithFirstAsset:firstAsset secondAsset:secondAsset];
```


五、视频加滤镜功能
======

5.1 单个滤镜
---------------

``` bash
// 素描滤镜
GPUImageBrightnessFilter *newFilter = [[GPUImageBrightnessFilter alloc] init];
newFilter.brightness = 0.4f;
self.filter = newFilter;
```

5.2 组合滤镜
----------
``` bash
GPUImageRGBFilter *filter1         = [[GPUImageRGBFilter alloc] init];
GPUImageToonFilter *filter2        = [[GPUImageToonFilter alloc] init];
GPUImageColorInvertFilter *filter3 = [[GPUImageColorInvertFilter alloc] init];
GPUImageSepiaFilter       *filter4 = [[GPUImageSepiaFilter alloc] init];
[(GPUImageFilterGroup *)_filter addFilter:filter1];
[(GPUImageFilterGroup *)_filter addFilter:filter2];
[(GPUImageFilterGroup *)_filter addFilter:filter3];
[(GPUImageFilterGroup *)_filter addFilter:filter4];

[filter1 addTarget:filter2];
[filter2 addTarget:filter3];
[filter3 addTarget:filter4];
              
[(GPUImageFilterGroup *)_filter setInitialFilters:[NSArray arrayWithObject:filter1]];
[(GPUImageFilterGroup *)_filter setTerminalFilter:filter4];
```


5.3 添加滤镜
------------
``` bash
// imageMovie
self.movieFile = [[GPUImageMovie alloc] initWithURL:_playUrl];
_movieFile.runBenchmark = YES;
_movieFile.playAtActualSpeed = NO;
// 滤镜
[_movieFile addTarget:_filter];
// GPUImageView
GPUImageView *filterView = [[GPUImageView alloc] init];
[_filter addTarget:filterView];
     
// MovieWriter
self.movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:_currentMovieUrl size:CGSizeMake(480.0, 640.0)];
[_filter addTarget:_movieWriter];
        
_movieWriter.shouldPassthroughAudio = YES;
_movieFile.audioEncodingTarget = _movieWriter;
[_movieFile enableSynchronizedEncodingUsingMovieWriter:_movieWriter];

// 开始处理
[_movieWriter startRecording];
[_movieFile startProcessing];

[self.player pause];
 _processing.hidden = NO;
 [_movieWriter setCompletionBlock:^{
	 [_filter removeTarget:_movieWriter];
	 [_movieWriter finishRecording];
	 dispatch_async(dispatch_get_main_queue(), ^{
		 _processing.hidden = YES;
     });
}];
```


六、视频加MV功能
=====
- 代码有点乱，累了，不想整理了，大多同理吧。

``` bash
#pragma mark -
#pragma mark - 🍎mv处理 1314
// 加mv处理
- (void)processMovieByMVUrl:(NSURL *)mvUrl {

    AVURLAsset *firstAsset = [AVURLAsset URLAssetWithURL:_playUrl options:nil];
    AVURLAsset *secondAsset = [AVURLAsset URLAssetWithURL:mvUrl options:nil];
 
    if (firstAsset.duration.value != 0 && secondAsset.duration.value != 0) {
        // 1 - Create AVMutableComposition object. This object will hold your AVMutableCompositionTrack instances.
        AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
        // 2 - Create two video tracks
        AVMutableCompositionTrack *firstTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                            preferredTrackID:kCMPersistentTrackID_Invalid];
        [firstTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                            ofTrack:[[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                             atTime:kCMTimeZero
                              error:nil];
        AVMutableCompositionTrack *secondTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                             preferredTrackID:kCMPersistentTrackID_Invalid];
        [secondTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                             ofTrack:[[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                              atTime:kCMTimeZero // 🌲改
                               error:nil];
        
        // 2.1 - Create AVMutableVideoCompositionInstruction
        AVMutableVideoCompositionInstruction *mainInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
        mainInstruction.timeRange = CMTimeRangeMake(kCMTimeZero,
                                                    firstAsset.duration);
        
        // 2.2 - Create an AVMutableVideoCompositionLayerInstruction for the first track
        AVMutableVideoCompositionLayerInstruction *firstlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:firstTrack];
        AVAssetTrack *firstAssetTrack = [[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        UIImageOrientation firstAssetOrientation_  = UIImageOrientationUp;
        BOOL isFirstAssetPortrait_  = NO;
        CGAffineTransform firstTransform = firstAssetTrack.preferredTransform;
        if (firstTransform.a == 0 && firstTransform.b == 1.0 && firstTransform.c == -1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ = UIImageOrientationRight;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 0 && firstTransform.b == -1.0 && firstTransform.c == 1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ =  UIImageOrientationLeft;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == 1.0) {
            firstAssetOrientation_ =  UIImageOrientationUp;
        }
        if (firstTransform.a == -1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == -1.0) {
            firstAssetOrientation_ = UIImageOrientationDown;
        }
        [firstlayerInstruction setTransform:firstAsset.preferredTransform atTime:kCMTimeZero];
       
        // 2.3 - Create an AVMutableVideoCompositionLayerInstruction for the second track
        AVMutableVideoCompositionLayerInstruction *secondlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:secondTrack];
        AVAssetTrack *secondAssetTrack = [[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];

        UIImageOrientation secondAssetOrientation_  = UIImageOrientationUp;
        BOOL isSecondAssetPortrait_ = NO;
        CGAffineTransform secondTransform = secondAssetTrack.preferredTransform;
        if (secondTransform.a == 0 && secondTransform.b == 1.0 && secondTransform.c == -1.0 && secondTransform.d == 0) {
            secondAssetOrientation_= UIImageOrientationRight;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 0 && secondTransform.b == -1.0 && secondTransform.c == 1.0 && secondTransform.d == 0) {
            secondAssetOrientation_ =  UIImageOrientationLeft;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == 1.0) {
            secondAssetOrientation_ =  UIImageOrientationUp;
        }
        if (secondTransform.a == -1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == -1.0) {
            secondAssetOrientation_ = UIImageOrientationDown;
        }
//        [secondlayerInstruction setTransform:secondAsset.preferredTransform atTime:firstAsset.duration];
        [secondlayerInstruction setTransform:secondAsset.preferredTransform atTime:kCMTimeZero];
        
        // 2.4 - Add instructions
        mainInstruction.layerInstructions = [NSArray arrayWithObjects:firstlayerInstruction, secondlayerInstruction,nil];
        AVMutableVideoComposition *mainCompositionInst = [AVMutableVideoComposition videoComposition];
        mainCompositionInst.instructions = [NSArray arrayWithObject:mainInstruction];
        mainCompositionInst.frameDuration = CMTimeMake(1, firstAsset.duration.value/firstAsset.duration.timescale);
        
        CGSize naturalSizeFirst, naturalSizeSecond;
        if(isFirstAssetPortrait_){
            naturalSizeFirst = CGSizeMake(firstAssetTrack.naturalSize.height, firstAssetTrack.naturalSize.width);
        } else {
            naturalSizeFirst = firstAssetTrack.naturalSize;
        }
        if(isSecondAssetPortrait_){
            naturalSizeSecond = CGSizeMake(secondAssetTrack.naturalSize.height, secondAssetTrack.naturalSize.width);
        } else {
            naturalSizeSecond = secondAssetTrack.naturalSize;
        }
        
        float renderWidth, renderHeight;
        if(naturalSizeFirst.width > naturalSizeSecond.width) {
            renderWidth = naturalSizeFirst.width;
        } else {
            renderWidth = naturalSizeSecond.width;
        }
        if(naturalSizeFirst.height > naturalSizeSecond.height) {
            renderHeight = naturalSizeFirst.height;
        } else {
            renderHeight = naturalSizeSecond.height;
        }
//        [secondAsset increaseSize:[NSValue valueWithCGSize:CGSizeMake(480, 640)]];
        [firstlayerInstruction setOpacity:0.5 atTime:kCMTimeZero]; //r34645🍎
//        [secondlayerInstruction setOpacity:0.5 atTime:kCMTimeZero]; //r34645🍎
        
        // 480, 640
        CGFloat result = renderWidth < renderHeight ? renderWidth : renderHeight;
        mainCompositionInst.renderSize = CGSizeMake(result, result);

        // 3 - Audio track
        AVAsset *audioAsset = [AVAsset assetWithURL:_currentSoundUrl];
        if (audioAsset!=nil) {
            AVMutableCompositionTrack *AudioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];
            [AudioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration) ofTrack:[[audioAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0] atTime:kCMTimeZero error:nil];
        }
        
        // 4 - Get path
        NSURL *url = [self fileURLForFilterMovieByName:mvFile];
        [self removeFile:url];
        mvFile ++;
        // 5 - Create exporter
        AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:mixComposition
                                                                          presetName:AVAssetExportPresetHighestQuality];
        exporter.outputURL=url;
        exporter.outputFileType = AVFileTypeQuickTimeMovie;
        exporter.shouldOptimizeForNetworkUse = YES;
        exporter.videoComposition = mainCompositionInst; // 加
        [exporter exportAsynchronouslyWithCompletionHandler:^{
            dispatch_async(dispatch_get_main_queue(), ^{
                [self exportDidFinish:exporter];
            });
        }];
    }
}
```


七、学习
======
- [GPUImage详细解析（六）-用视频做视频水印](http://www.jianshu.com/p/722d65bac58d)
- [AVAsset、AVMutableComposition系列类的理解及视频裁剪示例
](http://blog.csdn.net/xiaolinyeyi/article/details/50878996)
- [iOS GPUImage之GPUImageFilterGroup组合滤镜（5）](http://blog.csdn.net/merrygoot/article/details/51804906)
- [AVFoundation和GPUImage初探](http://www.tuicool.com/articles/FVnumu)
- [GPUImage.h简单说明](http://blog.csdn.net/think_ma/article/details/43093331)

