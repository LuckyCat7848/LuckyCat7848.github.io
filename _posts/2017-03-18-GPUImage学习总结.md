---
layout: post
title:  GPUImageå­¦ä¹ æ€»ç»“
date:   2017-03-18 01:43:12 +0800
categories: æŠ€æœ¯
tag: Object-C
---


* TOC
{:toc}




ä¸€ã€ä»‹ç»
===========
GPUImageæ˜¯Brad Larsonåœ¨githubæ‰˜ç®¡çš„å¼€æºé¡¹ç›®ã€‚

GPUImageæ˜¯ä¸€ä¸ªåŸºäºGPUå›¾åƒå’Œè§†é¢‘å¤„ç†çš„å¼€æºiOSæ¡†æ¶ï¼Œæä¾›å„ç§å„æ ·çš„å›¾åƒå¤„ç†æ»¤é•œï¼Œå¹¶ä¸”æ”¯æŒç…§ç›¸æœºå’Œæ‘„åƒæœºçš„å®æ—¶æ»¤é•œï¼› åŸºäºGPUçš„å›¾åƒåŠ é€Ÿï¼Œå› æ­¤å¯ä»¥åŠ é€Ÿå¯¹å®æ—¶æ‘„åƒå¤´è§†é¢‘ã€ç”µå½±ä»¥åŠimageçš„æ»¤é•œå’Œå…¶å®ƒæ•ˆæœå¤„ç†ï¼Œå¹¶ä¸”èƒ½å¤Ÿè‡ªå®šä¹‰å›¾åƒæ»¤é•œã€‚å¦å¤–ï¼Œ GPUImageæ”¯æŒARCã€‚

ä½¿ç”¨GPUImageå¤„ç†å›¾ç‰‡æ¯”Core Imageæ›´ç®€å•ï¼Œåªéœ€è¦å°†è¿‡æ»¤å™¨èµ‹ç»™å›¾ç‰‡å¯¹è±¡å³å¯ï¼Œä¸ç”¨è€ƒè™‘contextæˆ–è€…è®¾å¤‡ç­‰å…¶ä»–é—®é¢˜ã€‚GPUImageæä¾›äº†é™¤é«˜æ–¯æ¨¡ç³Šå¤–çš„å…¶ä»–å‡ ç§ä¸åŒæ•ˆæœçš„æ¨¡ç³Šï¼Œè™½ç„¶Core Imageä¹Ÿæä¾›äº†å‡ ç§æ¨¡ç³Šæ•ˆæœï¼Œä½†ç›®å‰åœ¨iOSä¸Šèƒ½ç”¨çš„å°±åªæœ‰é«˜æ–¯æ¨¡ç³Šï¼Œè€ŒGPUImageå¯ç”¨çš„æœ‰FastBlur, GaussianBlur, GaussianSelectiveBlur å’Œ BoxBlurã€‚æ­¤å¤–ï¼Œä½œä¸ºå¼€æºæ¡†æ¶çš„GPUImageè¿˜æ”¯æŒè‡ªå®šä¹‰çš„è¿‡æ»¤å™¨ã€‚



äºŒã€å†…ç½®æ»¤é•œ
======
å…±125ä¸ªæ»¤é•œ, åˆ†ä¸ºå››ç±»
Color adjustments: 31 filters, é¢œè‰²å¤„ç†ç›¸å…³
Image processing: 40 filters, å›¾åƒå¤„ç†ç›¸å…³.
Blending modes: 29 filters, æ··åˆæ¨¡å¼ç›¸å…³.
Visual effects: 25 filters, è§†è§‰æ•ˆæœç›¸å…³.


ä¸‰ã€åˆ†æ®µå½•åˆ¶
======
å‚è€ƒ[AVFoundationå’ŒGPUImageåˆæ¢](http://www.tuicool.com/articles/FVnumu)ã€‚ 

åˆ†æ®µå½•åˆ¶ï¼Œæ¯æ¬¡å½•åˆ¶éƒ½è¦åˆ›å»ºä¸€ä¸ªmovieWriterï¼Œæ¯æ¬¡éƒ½ä¼šåœ¨é‡æ–°åˆ›å»ºmovieWriterå¹¶å°†å®ƒè®¾ç½®ä¸ºvideoCameraçš„ audioEncodingTarget æ—¶å€™ï¼Œç•Œé¢éƒ½ä¼šå¡é¡¿ä¸€ä¸‹ï¼Œè¿™æ˜¯å› ä¸ºvideoCameraé»˜è®¤æ˜¯ä¸å½•åˆ¶å£°éŸ³çš„ï¼Œè€Œæ¯æ¬¡åˆ›å»ºmovieWriterçš„æ—¶å€™éƒ½ç”¨åˆ°äº† movieWriter.hasAudioTrack = YESï¼Œè°ƒç”¨è¿™ä¸ªä¹‹åvideoCameraä¼šè‡ªåŠ¨å»æ·»åŠ å£°éŸ³è¾“å…¥æºï¼Œå‡†å¤‡ä¸€äº›æ•°æ®ï¼Œæ‰€ä»¥è¿™ä¸ªè¿‡ç¨‹ä¼šå¯¼è‡´ç•Œé¢å¡é¡¿ä¸€ä¸‹ï¼Œä¸‹é¢è¿™å¥ä»£ç å¾ˆé‡è¦ï¼š

```bash
â€“ (BOOL)addAudioInputsAndOutputs;
```

videoCameraçš„å¤´æ–‡ä»¶çš„æ³¨é‡Šæ˜¯ï¼šå½•åˆ¶çš„æ—¶å€™æ·»åŠ å£°éŸ³ï¼Œæ·»åŠ è¾“å…¥æºå’Œè¾“å‡ºæºä¼šæš‚æ—¶ä¼šä½¿å½•åˆ¶æš‚æ—¶å¡ä½ï¼Œæ‰€ä»¥åœ¨è¦ä½¿ç”¨å£°éŸ³çš„æƒ…å†µä¸‹è¦`å…ˆ`è°ƒç”¨è¯¥æ–¹æ³•æ¥é˜²æ­¢å½•åˆ¶è¢«å¡ä½ã€‚



å››ã€ GPUImageå½•åˆ¶è§†é¢‘
=====
è½¬è‡ª[GPUImage å½•åˆ¶è§†é¢‘æ³¨æ„äº‹é¡¹](http://blog.sina.com.cn/s/blog_d0c0c80c0102xbo0.html)ï¼Œæ„Ÿè°¢[æˆ‘çš„ä¸ªç¥å•Š](http://blog.sina.com.cn/u/3502295052)çš„åˆ†äº«ã€‚ 

4.1 åŸºæœ¬è®¾ç½®
------------------------------------

``` bash
// åˆ›å»ºæ‘„åƒå¤´
self.videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPreset640x480 cameraPosition:AVCaptureDevicePositionBack];

self.videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait; // è¾“å‡ºå›¾åƒæ—‹è½¬æ–¹å¼
self.videoCamera.horizontallyMirrorFrontFacingCamera = YES;

// åˆ›å»ºç•Œé¢æ˜¾ç¤ºæ‘„åƒå†…å®¹
self.gpuImageView = [[GPUImageView alloc] initWithFrame:frame];
self.gpuImageView.fillMode = kGPUImageFillModePreserveAspectRatioAndFill; // æ˜¾ç¤ºæ¨¡å¼å……æ»¡æ•´ä¸ªè¾¹æ¡†
self.gpuImageView.clipsToBounds = YES;
[self.gpuImageView.layer setMasksToBounds:YES];

// æ»¤é•œ
self.filter = [[GPUImageBrightnessFilter alloc] init];
self.filter.brightness = 0.1f;
```

4.2 å¼€å§‹å½•åˆ¶
------------------------------------

``` bash
// è¯¥å¥å¯é˜²æ­¢å…è®¸å£°éŸ³é€šè¿‡çš„æƒ…å†µä¸‹ï¼Œé¿å…å½•åˆ¶ç¬¬ä¸€å¸§é»‘å±é—ªå±å¡é¡¿ç°è±¡ï¼ˆåˆ†æ®µå½•åˆ¶é‡Œæœ‰è¯¦è§£ï¼‰
[_camera addAudioInputsAndOutputs];

// é…ç½®å½•åˆ¶å™¨
NSURL * saveURL = [self fileURLForTempMovieByName:[NSString stringWithFormat:@"%d", videoFileNum]]; // åˆ†æ®µå½•åˆ¶,videoFileNum:ç¬¬å‡ æ®µ
self.movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:saveURL  size:CGSizeMake(480.0f, 640.0f)];

self.movieWriter.assetWriter.movieFragmentInterval = kCMTimeInvalid;
self.movieWriter.encodingLiveVideo = YES; // å½±å“å…¶å®æ˜¯expectsMediaDataInRealTimeå±æ€§ï¼ŒYESæ—¶ç”¨äºè¾“å…¥æµæ˜¯å®æ—¶çš„,æ¯”å¦‚è¯´æ‘„åƒå¤´
self.movieWriter.hasAudioTrack = YES; // å¼€å¯å£°éŸ³é‡‡é›†
self.movieWriter.shouldPassthroughAudio = YES; // æ˜¯å¦ä½¿ç”¨æºéŸ³æº

[self.filter addTarget:self.movieWriter]; // æ»¤é•œæ·»åŠ è‡³moviewrite
[self.filter addTarget:self.gpuImageView]; // æ»¤é•œæ·»åŠ gpuimageview
self.videoCamera.audioEncodingTarget = self.movieWriter; // éŸ³é¢‘æ¥æºæ˜¯æ–‡ä»¶

// å¼€å§‹å½•åˆ¶
[self.videoCamera startCameraCapture];
[self.movieWriter startRecording];
```

4.3 åœæ­¢å½•åˆ¶
------------------------------------

``` bash
[self.filter removeTarget:self.movieWriter];
[self.movieWriter finishRecording];
self.videoCamera.audioEncodingTarget = nil;
```

4.4 è§†é¢‘æ‹¼æ¥
------------------------------------

- 4.4.1 AVFoundationåŸºæœ¬çŸ¥è¯†ç‚¹

AVAssetï¼šåª’ä½“ã€‚

AVAssetTrackï¼šåª’ä½“è½¨é“ã€‚

AVMutableComposition ï¼šåŒ…å«äº†ä¸€ä¸ªæˆ–å¤šä¸ªç»™å®šç±»å‹çš„åª’ä½“è½¨é“çš„å®¹å™¨ã€‚ 

AVMutableCompositionTrack ï¼šå·¥ç¨‹æ–‡ä»¶ä¸­çš„è½¨é“ï¼Œæœ‰éŸ³é¢‘è½¨ã€è§†é¢‘è½¨ç­‰ï¼Œé‡Œé¢å¯ä»¥æ’å…¥å„ç§å¯¹åº”çš„ç´ æã€‚

AVMutableVideoCompositionï¼šç”¨æ¥ç”Ÿæˆvideoçš„ç»„åˆæŒ‡ä»¤ï¼ŒåŒ…å«å¤šæ®µinstructionï¼Œå¯ä»¥å†³å®šæœ€ç»ˆè§†é¢‘çš„å°ºå¯¸ã€‚ 

AVMutableVideoCompositionInstructionï¼šå†³å®šä¸€ä¸ªtimeRangeå†…æ¯ä¸ªè½¨é“çš„çŠ¶æ€ï¼ŒåŒ…å«å¤šä¸ªlayerInstructionã€‚

AVMutableVideoCompositionLayerInstructionï¼šå†³å®šè§†é¢‘è½¨é“çš„æ•ˆæœ:æ¨¡ç³Šã€å˜å½¢ã€è£å‰ª,å¯åˆ›å»ºå‡ºè¿‡æ¸¡æ•ˆæœã€‚ 


- 4.4.2 åˆ†æ®µè§†é¢‘çš„æ‹¼æ¥

``` bash
#pragma mark -
#pragma mark è§†é¢‘æ‹¼æ¥,è§†é¢‘å’ŒéŸ³é¢‘åˆæˆ å­˜å‚¨ä¸º:MergerMovie
- (void)mergeAndSaveMovieWithFirstAsset:(AVAsset * )firstAsset secondAsset:(AVAsset *)secondAsset {
    
    static int mergerFileNum = 1; // åˆæˆåçš„è§†é¢‘æ–‡ä»¶ä¸ªæ•°(å› ä¸ºæ˜¯é€’å½’åˆæˆ,ä¸ä¾¿åˆ é™¤ä¸Šä¸€ä¸ª,æ‰€ä»¥æœ‰å¤šä¸ªæ–‡ä»¶)
    
    if (firstAsset !=nil && secondAsset!=nil) {
        // 1.åˆ›å»ºç»„åˆmixComposition,ç”¨äºåˆæˆè§†é¢‘,å’Œå£°éŸ³(è¦åˆ†åˆ«åˆ›å»ºç»„åˆè½¨é“)
        AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
        // 2.åˆ›å»º1å’Œ2çš„è§†é¢‘è½¨é“ã€éŸ³é¢‘è½¨é“,éƒ½åŠ å…¥ç»„åˆä¸­mixComposition
        AVMutableCompositionTrack *firstVideoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                                 preferredTrackID:kCMPersistentTrackID_Invalid];
        [firstVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                                 ofTrack:[[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                                  atTime:kCMTimeZero
                                   error:nil];
        AVMutableCompositionTrack *firstAudioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio
                                                                                 preferredTrackID:kCMPersistentTrackID_Invalid];
        [firstAudioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                                 ofTrack:[[firstAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0]
                                  atTime:kCMTimeZero
                                   error:nil];
        
        
        AVMutableCompositionTrack *secondVideoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                                  preferredTrackID:kCMPersistentTrackID_Invalid];
        [secondVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, secondAsset.duration)
                                  ofTrack:[[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                                   atTime:firstAsset.duration
                                    error:nil];
        AVMutableCompositionTrack *secondAudioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio
                                                                                  preferredTrackID:kCMPersistentTrackID_Invalid];
        [secondAudioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, secondAsset.duration)
                                  ofTrack:[[secondAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0]
                                   atTime:firstAsset.duration
                                    error:nil];
        
        // 3.åˆ›å»ºAVMutableVideoCompositionInstruction:ä¸€ä¸ªæŒ‡ä»¤ï¼Œå†³å®šä¸€ä¸ªtimeRangeå†…æ¯ä¸ªè½¨é“çš„çŠ¶æ€ï¼ŒåŒ…å«å¤šä¸ªlayerInstruction
        AVMutableVideoCompositionInstruction *mainInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
        mainInstruction.timeRange = CMTimeRangeMake(kCMTimeZero, CMTimeAdd(firstAsset.duration, secondAsset.duration));
        
        // 3-1.åˆ›å»ºç¬¬ä¸€ä¸ªAVMutableVideoCompositionLayerInstruction:å†³å®šè§†é¢‘è½¨é“çš„æ•ˆæœ:æ¨¡ç³Šã€å˜å½¢ã€è£å‰ª,å¯åˆ›å»ºå‡ºè¿‡æ¸¡æ•ˆæœ
        AVMutableVideoCompositionLayerInstruction *firstlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:firstVideoTrack];
        AVAssetTrack *firstAssetTrack = [[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        UIImageOrientation firstAssetOrientation_  = UIImageOrientationUp;
        BOOL isFirstAssetPortrait_  = NO;
        CGAffineTransform firstTransform = firstAssetTrack.preferredTransform;
        if (firstTransform.a == 0 && firstTransform.b == 1.0 && firstTransform.c == -1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ = UIImageOrientationRight;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 0 && firstTransform.b == -1.0 && firstTransform.c == 1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ =  UIImageOrientationLeft;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == 1.0) {
            firstAssetOrientation_ =  UIImageOrientationUp;
        }
        if (firstTransform.a == -1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == -1.0) {
            firstAssetOrientation_ = UIImageOrientationDown;
        }
        [firstlayerInstruction setTransform:firstAsset.preferredTransform atTime:kCMTimeZero];
        [firstlayerInstruction setOpacity:0.0 atTime:firstAsset.duration];
        
        // 3-2.åˆ›å»ºç¬¬äºŒä¸ªAVMutableVideoCompositionLayerInstruction
        AVMutableVideoCompositionLayerInstruction *secondlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:secondVideoTrack];
        AVAssetTrack *secondAssetTrack = [[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        UIImageOrientation secondAssetOrientation_  = UIImageOrientationUp;
        BOOL isSecondAssetPortrait_ = NO;
        CGAffineTransform secondTransform = secondAssetTrack.preferredTransform;
        if (secondTransform.a == 0 && secondTransform.b == 1.0 && secondTransform.c == -1.0 && secondTransform.d == 0) {
            secondAssetOrientation_= UIImageOrientationRight;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 0 && secondTransform.b == -1.0 && secondTransform.c == 1.0 && secondTransform.d == 0) {
            secondAssetOrientation_ =  UIImageOrientationLeft;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == 1.0) {
            secondAssetOrientation_ =  UIImageOrientationUp;
        }
        if (secondTransform.a == -1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == -1.0) {
            secondAssetOrientation_ = UIImageOrientationDown;
        }
        [secondlayerInstruction setTransform:secondAsset.preferredTransform atTime:firstAsset.duration];
        
        // AVMutableVideoComposition:ç”¨æ¥ç”Ÿæˆvideoçš„ç»„åˆæŒ‡ä»¤,åŒ…å«å¤šæ®µinstruction,å¯ä»¥å†³å®šæœ€ç»ˆè§†é¢‘çš„å°ºå¯¸
        // 3-3.AVMutableVideoCompositionæ·»åŠ instructions
        mainInstruction.layerInstructions = [NSArray arrayWithObjects:firstlayerInstruction, secondlayerInstruction,nil];
        AVMutableVideoComposition *mainCompositionInst = [AVMutableVideoComposition videoComposition];
        mainCompositionInst.instructions = [NSArray arrayWithObject:mainInstruction];
        mainCompositionInst.frameDuration = CMTimeMake(1, 30);
        
        CGSize naturalSizeFirst, naturalSizeSecond;
        if(isFirstAssetPortrait_){
            naturalSizeFirst = CGSizeMake(firstAssetTrack.naturalSize.height, firstAssetTrack.naturalSize.width);
        } else {
            naturalSizeFirst = firstAssetTrack.naturalSize;
        }
        if(isSecondAssetPortrait_){
            naturalSizeSecond = CGSizeMake(secondAssetTrack.naturalSize.height, secondAssetTrack.naturalSize.width);
        } else {
            naturalSizeSecond = secondAssetTrack.naturalSize;
        }
        
        float renderWidth, renderHeight;
        renderWidth = naturalSizeFirst.width > naturalSizeSecond.width ? naturalSizeFirst.width : naturalSizeSecond.width;
        renderHeight = naturalSizeFirst.height > naturalSizeSecond.height ? naturalSizeFirst.height : naturalSizeSecond.height;
        mainCompositionInst.renderSize = CGSizeMake(renderWidth, renderHeight);
        
        // 4.è·å–è·¯å¾„
        NSURL *url = [self fileURLForTempMovieByName:[NSString stringWithFormat:@"MergerMovie%d", mergerFileNum]];
        
        // 5.åˆ›å»ºAVAssetExportSession,ç”¨äºå¯¼å‡ºåˆæˆå¥½çš„è§†é¢‘
        AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:mixComposition
                                                                          presetName:AVAssetExportPresetHighestQuality];
        exporter.outputURL=url;
        exporter.outputFileType = AVFileTypeMPEG4;//AVFileTypeQuickTimeMovie;
        exporter.shouldOptimizeForNetworkUse = YES;
        exporter.videoComposition = mainCompositionInst;
        __weak __typeof(self)weakSelf = self;
        [exporter exportAsynchronouslyWithCompletionHandler:^{
            dispatch_async(dispatch_get_main_queue(), ^{
                mergerFileNum ++;
                if (mergerFileNum < [_videoArray count]) {
                    // å–åˆæˆå¥½çš„è§†é¢‘å’Œä¸‹ä¸€ä¸ª,é€’å½’è¿›è¡Œè§†é¢‘æ‹¼æ¥,æ‹¼æ¥åå’ŒéŸ³é¢‘åˆæˆ
                    AVAsset * nextAsset = [AVAsset assetWithURL:[_videoArray objectAtIndex:mergerFileNum]];
                    AVAsset * mergerVideo = [AVAsset assetWithURL:[weakSelf fileURLForTempMovieByName:[NSString stringWithFormat:@"MergerMovie%d", mergerFileNum - 1]]];
                    [weakSelf mergeAndSaveMovieWithFirstAsset:mergerVideo secondAsset:nextAsset];
                } else {
                    // åˆæˆå®Œæˆ,å¯¼å‡º
                    mergerFileFinally = [NSString stringWithFormat:@"MergerMovie%d", mergerFileNum - 1];
                    mergerFileNum = 1;
                    [weakSelf exportDidFinish:exporter];
                }
            });
        }];
    }
}
- (void)exportDidFinish:(AVAssetExportSession*)session {
    __weak __typeof(self)weakSelf = self;
    dispatch_async(dispatch_get_main_queue(), ^{
        if (session.status == AVAssetExportSessionStatusCompleted) {
            // è§†é¢‘æ‹¼æ¥æˆåŠŸ,å–å‡ºè§†é¢‘ä¸­çš„éŸ³é¢‘
            [weakSelf getAudioSound];
        } else {
            UIAlertView *alert = [[UIAlertView alloc] initWithTitle:@"Video Saved" message:[NSString stringWithFormat:@"Saved To File Failed -- %d", session.status]
                                                           delegate:self cancelButtonTitle:@"OK" otherButtonTitles:nil];
            [alert show];
        }
    });
}
```

- 4.4.3 ä»åˆæˆçš„è§†é¢‘å–å‡ºéŸ³é¢‘è½¨é“

``` bash
// ä»åˆæˆå¥½çš„è§†é¢‘ä¸­è·å–éŸ³é¢‘
- (void)getAudioSound {
    AVURLAsset *videoAsset = [AVURLAsset URLAssetWithURL:[self fileURLForTempMovieByName:mergerFileFinally] options:nil];
    AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
    //åˆ›å»ºä¸€ä¸ªç»„åˆè½¨é“,ç±»å‹æ˜¯AVMediaTypeAudio
    AVMutableCompositionTrack *audioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio
                                                                        preferredTrackID:kCMPersistentTrackID_Invalid];
    
    //è·å–videoAssetä¸­çš„éŸ³é¢‘è½¨é“,æ’å…¥ç»„åˆè½¨é“
    [audioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, videoAsset.duration)
                        ofTrack:[[videoAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0] atTime:kCMTimeZero error:nil];
    
    NSString *outFilePath = [[self fileURLForTempSoundByName:@"MergerSound"] path];
    [self exportAudioAsset:audioTrack.asset toFilePath:outFilePath];
}
- (BOOL)exportAudioAsset:(AVAsset *)avAsset toFilePath:(NSString *)filePath {
    AVAssetExportSession *exportSession = [AVAssetExportSession
                                           exportSessionWithAsset:avAsset
                                           presetName:AVAssetExportPresetAppleM4A];
    if (nil == exportSession) return NO;//åˆ›å»ºå¤±è´¥ï¼Œåˆ™è·³å‡º
    
    exportSession.outputURL = [NSURL fileURLWithPath:filePath]; // output path æ–°æ–‡ä»¶è·¯å¾„
    exportSession.outputFileType = AVFileTypeAppleM4A; // output file type æ–°æ–‡ä»¶ç±»å‹
    
    __weak __typeof(self)weakSelf = self;
    [exportSession exportAsynchronouslyWithCompletionHandler:^{ //block
        if (exportSession.status == AVAssetExportSessionStatusCompleted) {
            dispatch_async(dispatch_get_main_queue(), ^{
                // 1.æ ¹æ® Main.storyboard çš„å‰ç¼€ "Main" å–åˆ°storyBoard çš„åœ°å€
                UIStoryboard *storyBoard = [UIStoryboard storyboardWithName:@"Recording" bundle:[NSBundle mainBundle]];
                // 2.æ ¹æ®äº‹å…ˆåœ¨storyBoardä¸­è®¾ç½®çš„ storyBoard ID æ¥è·å–ç›¸åº”çš„ ViewController
                VideoPlayViewController * videoPlay = [storyBoard instantiateViewControllerWithIdentifier:@"VideoPlayViewController"];
                videoPlay.playUrl = [weakSelf fileURLForTempMovieByName:mergerFileFinally];
                videoPlay.playSoundUrl = [weakSelf fileURLForTempSoundByName:@"MergerSound"];
                [weakSelf.navigationController pushViewController:videoPlay animated:YES];
            });
        } else {
            dispatch_async(dispatch_get_main_queue(), ^{
                UIAlertView *alert = [[UIAlertView alloc] initWithTitle:@"Audio Saved" message:@"Saved To File Failed"
                                                               delegate:self cancelButtonTitle:@"OK" otherButtonTitles:nil];
                [alert show];
            });
        }
    }];
    return YES;
}
```

- 4.4.4 è°ƒç”¨åˆæˆè§†é¢‘æ–¹æ³•ï¼š

``` bash
// å–ç¬¬1,2æ®µ,è¿›è¡Œè§†é¢‘æ‹¼æ¥,æ‹¼æ¥åå–å‡ºå®Œæ•´éŸ³é¢‘,ä¼ ç•Œé¢
AVAsset *firstAsset = [AVAsset assetWithURL:_videoArray[0]];
AVAsset *secondAsset = [AVAsset assetWithURL:_videoArray[1]];
[self mergeAndSaveMovieWithFirstAsset:firstAsset secondAsset:secondAsset];
```


äº”ã€è§†é¢‘åŠ æ»¤é•œåŠŸèƒ½
======

5.1 å•ä¸ªæ»¤é•œ
---------------

``` bash
// ç´ ææ»¤é•œ
GPUImageBrightnessFilter *newFilter = [[GPUImageBrightnessFilter alloc] init];
newFilter.brightness = 0.4f;
self.filter = newFilter;
```

5.2 ç»„åˆæ»¤é•œ
----------
``` bash
GPUImageRGBFilter *filter1         = [[GPUImageRGBFilter alloc] init];
GPUImageToonFilter *filter2        = [[GPUImageToonFilter alloc] init];
GPUImageColorInvertFilter *filter3 = [[GPUImageColorInvertFilter alloc] init];
GPUImageSepiaFilter       *filter4 = [[GPUImageSepiaFilter alloc] init];
[(GPUImageFilterGroup *)_filter addFilter:filter1];
[(GPUImageFilterGroup *)_filter addFilter:filter2];
[(GPUImageFilterGroup *)_filter addFilter:filter3];
[(GPUImageFilterGroup *)_filter addFilter:filter4];

[filter1 addTarget:filter2];
[filter2 addTarget:filter3];
[filter3 addTarget:filter4];
              
[(GPUImageFilterGroup *)_filter setInitialFilters:[NSArray arrayWithObject:filter1]];
[(GPUImageFilterGroup *)_filter setTerminalFilter:filter4];
```


5.3 æ·»åŠ æ»¤é•œ
------------
``` bash
// imageMovie
self.movieFile = [[GPUImageMovie alloc] initWithURL:_playUrl];
_movieFile.runBenchmark = YES;
_movieFile.playAtActualSpeed = NO;
// æ»¤é•œ
[_movieFile addTarget:_filter];
// GPUImageView
GPUImageView *filterView = [[GPUImageView alloc] init];
[_filter addTarget:filterView];
     
// MovieWriter
self.movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:_currentMovieUrl size:CGSizeMake(480.0, 640.0)];
[_filter addTarget:_movieWriter];
        
_movieWriter.shouldPassthroughAudio = YES;
_movieFile.audioEncodingTarget = _movieWriter;
[_movieFile enableSynchronizedEncodingUsingMovieWriter:_movieWriter];

// å¼€å§‹å¤„ç†
[_movieWriter startRecording];
[_movieFile startProcessing];

[self.player pause];
 _processing.hidden = NO;
 [_movieWriter setCompletionBlock:^{
	 [_filter removeTarget:_movieWriter];
	 [_movieWriter finishRecording];
	 dispatch_async(dispatch_get_main_queue(), ^{
		 _processing.hidden = YES;
     });
}];
```


å…­ã€è§†é¢‘åŠ MVåŠŸèƒ½
=====
- ä»£ç æœ‰ç‚¹ä¹±ï¼Œç´¯äº†ï¼Œä¸æƒ³æ•´ç†äº†ï¼Œå¤§å¤šåŒç†å§ã€‚

``` bash
#pragma mark -
#pragma mark - ğŸmvå¤„ç† 1314
// åŠ mvå¤„ç†
- (void)processMovieByMVUrl:(NSURL *)mvUrl {

    AVURLAsset *firstAsset = [AVURLAsset URLAssetWithURL:_playUrl options:nil];
    AVURLAsset *secondAsset = [AVURLAsset URLAssetWithURL:mvUrl options:nil];
 
    if (firstAsset.duration.value != 0 && secondAsset.duration.value != 0) {
        // 1 - Create AVMutableComposition object. This object will hold your AVMutableCompositionTrack instances.
        AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
        // 2 - Create two video tracks
        AVMutableCompositionTrack *firstTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                            preferredTrackID:kCMPersistentTrackID_Invalid];
        [firstTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                            ofTrack:[[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                             atTime:kCMTimeZero
                              error:nil];
        AVMutableCompositionTrack *secondTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo
                                                                             preferredTrackID:kCMPersistentTrackID_Invalid];
        [secondTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration)
                             ofTrack:[[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0]
                              atTime:kCMTimeZero // ğŸŒ²æ”¹
                               error:nil];
        
        // 2.1 - Create AVMutableVideoCompositionInstruction
        AVMutableVideoCompositionInstruction *mainInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
        mainInstruction.timeRange = CMTimeRangeMake(kCMTimeZero,
                                                    firstAsset.duration);
        
        // 2.2 - Create an AVMutableVideoCompositionLayerInstruction for the first track
        AVMutableVideoCompositionLayerInstruction *firstlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:firstTrack];
        AVAssetTrack *firstAssetTrack = [[firstAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        UIImageOrientation firstAssetOrientation_  = UIImageOrientationUp;
        BOOL isFirstAssetPortrait_  = NO;
        CGAffineTransform firstTransform = firstAssetTrack.preferredTransform;
        if (firstTransform.a == 0 && firstTransform.b == 1.0 && firstTransform.c == -1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ = UIImageOrientationRight;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 0 && firstTransform.b == -1.0 && firstTransform.c == 1.0 && firstTransform.d == 0) {
            firstAssetOrientation_ =  UIImageOrientationLeft;
            isFirstAssetPortrait_ = YES;
        }
        if (firstTransform.a == 1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == 1.0) {
            firstAssetOrientation_ =  UIImageOrientationUp;
        }
        if (firstTransform.a == -1.0 && firstTransform.b == 0 && firstTransform.c == 0 && firstTransform.d == -1.0) {
            firstAssetOrientation_ = UIImageOrientationDown;
        }
        [firstlayerInstruction setTransform:firstAsset.preferredTransform atTime:kCMTimeZero];
       
        // 2.3 - Create an AVMutableVideoCompositionLayerInstruction for the second track
        AVMutableVideoCompositionLayerInstruction *secondlayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:secondTrack];
        AVAssetTrack *secondAssetTrack = [[secondAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];

        UIImageOrientation secondAssetOrientation_  = UIImageOrientationUp;
        BOOL isSecondAssetPortrait_ = NO;
        CGAffineTransform secondTransform = secondAssetTrack.preferredTransform;
        if (secondTransform.a == 0 && secondTransform.b == 1.0 && secondTransform.c == -1.0 && secondTransform.d == 0) {
            secondAssetOrientation_= UIImageOrientationRight;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 0 && secondTransform.b == -1.0 && secondTransform.c == 1.0 && secondTransform.d == 0) {
            secondAssetOrientation_ =  UIImageOrientationLeft;
            isSecondAssetPortrait_ = YES;
        }
        if (secondTransform.a == 1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == 1.0) {
            secondAssetOrientation_ =  UIImageOrientationUp;
        }
        if (secondTransform.a == -1.0 && secondTransform.b == 0 && secondTransform.c == 0 && secondTransform.d == -1.0) {
            secondAssetOrientation_ = UIImageOrientationDown;
        }
//        [secondlayerInstruction setTransform:secondAsset.preferredTransform atTime:firstAsset.duration];
        [secondlayerInstruction setTransform:secondAsset.preferredTransform atTime:kCMTimeZero];
        
        // 2.4 - Add instructions
        mainInstruction.layerInstructions = [NSArray arrayWithObjects:firstlayerInstruction, secondlayerInstruction,nil];
        AVMutableVideoComposition *mainCompositionInst = [AVMutableVideoComposition videoComposition];
        mainCompositionInst.instructions = [NSArray arrayWithObject:mainInstruction];
        mainCompositionInst.frameDuration = CMTimeMake(1, firstAsset.duration.value/firstAsset.duration.timescale);
        
        CGSize naturalSizeFirst, naturalSizeSecond;
        if(isFirstAssetPortrait_){
            naturalSizeFirst = CGSizeMake(firstAssetTrack.naturalSize.height, firstAssetTrack.naturalSize.width);
        } else {
            naturalSizeFirst = firstAssetTrack.naturalSize;
        }
        if(isSecondAssetPortrait_){
            naturalSizeSecond = CGSizeMake(secondAssetTrack.naturalSize.height, secondAssetTrack.naturalSize.width);
        } else {
            naturalSizeSecond = secondAssetTrack.naturalSize;
        }
        
        float renderWidth, renderHeight;
        if(naturalSizeFirst.width > naturalSizeSecond.width) {
            renderWidth = naturalSizeFirst.width;
        } else {
            renderWidth = naturalSizeSecond.width;
        }
        if(naturalSizeFirst.height > naturalSizeSecond.height) {
            renderHeight = naturalSizeFirst.height;
        } else {
            renderHeight = naturalSizeSecond.height;
        }
//        [secondAsset increaseSize:[NSValue valueWithCGSize:CGSizeMake(480, 640)]];
        [firstlayerInstruction setOpacity:0.5 atTime:kCMTimeZero]; //r34645ğŸ
//        [secondlayerInstruction setOpacity:0.5 atTime:kCMTimeZero]; //r34645ğŸ
        
        // 480, 640
        CGFloat result = renderWidth < renderHeight ? renderWidth : renderHeight;
        mainCompositionInst.renderSize = CGSizeMake(result, result);

        // 3 - Audio track
        AVAsset *audioAsset = [AVAsset assetWithURL:_currentSoundUrl];
        if (audioAsset!=nil) {
            AVMutableCompositionTrack *AudioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];
            [AudioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstAsset.duration) ofTrack:[[audioAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0] atTime:kCMTimeZero error:nil];
        }
        
        // 4 - Get path
        NSURL *url = [self fileURLForFilterMovieByName:mvFile];
        [self removeFile:url];
        mvFile ++;
        // 5 - Create exporter
        AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:mixComposition
                                                                          presetName:AVAssetExportPresetHighestQuality];
        exporter.outputURL=url;
        exporter.outputFileType = AVFileTypeQuickTimeMovie;
        exporter.shouldOptimizeForNetworkUse = YES;
        exporter.videoComposition = mainCompositionInst; // åŠ 
        [exporter exportAsynchronouslyWithCompletionHandler:^{
            dispatch_async(dispatch_get_main_queue(), ^{
                [self exportDidFinish:exporter];
            });
        }];
    }
}
```


ä¸ƒã€å­¦ä¹ 
======
- [GPUImageè¯¦ç»†è§£æï¼ˆå…­ï¼‰-ç”¨è§†é¢‘åšè§†é¢‘æ°´å°](http://www.jianshu.com/p/722d65bac58d)
- [AVAssetã€AVMutableCompositionç³»åˆ—ç±»çš„ç†è§£åŠè§†é¢‘è£å‰ªç¤ºä¾‹
](http://blog.csdn.net/xiaolinyeyi/article/details/50878996)
- [iOS GPUImageä¹‹GPUImageFilterGroupç»„åˆæ»¤é•œï¼ˆ5ï¼‰](http://blog.csdn.net/merrygoot/article/details/51804906)
- [AVFoundationå’ŒGPUImageåˆæ¢](http://www.tuicool.com/articles/FVnumu)
- [GPUImage.hç®€å•è¯´æ˜](http://blog.csdn.net/think_ma/article/details/43093331)

